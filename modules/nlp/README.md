# Aloy NLP Python v1

Servi√ßo de Processamento de Linguagem Natural para o ecossistema Aloy Microservices.

## üîÑ Comandos Suportados

O servi√ßo atualmente suporta os seguintes comandos:

### üí° Controle de Ilumina√ß√£o (`lamp_control`)

Permite controlar dispositivos de ilumina√ß√£o inteligente atrav√©s de comandos de voz.

- **A√ß√µes suportadas:**
  - `turn_on` - Ligar/acender uma luz
  - `turn_off` - Desligar/apagar uma luz
  - `set_color` - Mudar a cor da luz
  - `set_intensity` - Ajustar o brilho/intensidade da luz

- **Exemplos de frases:**
  - "Acenda a luz do quarto"
  - "Apague a luz da sala"
  - "Mude a cor da l√¢mpada da sala para azul"
  - "Ajuste a intensidade da luz da cozinha para 50%"

- **Estrutura da resposta JSON:**
  ```json
  {
    "type": "lamp_control",
    "message": "Luz da sala acesa com sucesso",
    "data": {
      "action": "turn_on",
      "room": "sala",
      "color": "branco",
      "intensity": "100"
    }
  }
  ```

### ‚è∞ Alarme e Lembretes

Comandos para definir alarmes e lembretes ainda aguardando implementa√ß√£o completa.

## üîç Processamento de Comandos

O sistema possui dois m√©todos para processar comandos:

### ‚úÖ Processamento Direto (Sem LLM)

Para comandos com formato conhecido e predefinido, como controle de l√¢mpadas, o sistema pode processar diretamente sem depender do LLM, garantindo:

- Menor lat√™ncia na resposta
- Opera√ß√£o mesmo quando o LLM n√£o est√° dispon√≠vel
- Maior consist√™ncia nas respostas

Implementado para comandos:
- `lamp_control` - Controle completo de ilumina√ß√£o

### üß† Processamento via LLM

Para comandos mais complexos ou que necessitam interpreta√ß√£o avan√ßada, o sistema utiliza o LLM configurado:

- Maior flexibilidade na interpreta√ß√£o
- Capacidade de lidar com linguagem natural amb√≠gua
- Adaptabilidade a novos formatos de comando

## üõ†Ô∏è Configura√ß√£o de Ambiente

O projeto utiliza vari√°veis de ambiente para configura√ß√£o. Essas vari√°veis est√£o definidas no arquivo `.env.local`.

### Principais Configura√ß√µes

```
# Configura√ß√µes da API do NLP
NLP_API_HOST=0.0.0.0       # Host da API
NLP_API_PORT=1200          # Porta da API (padr√£o definido no arquivo global)

# Configura√ß√µes do Modelo LLM
LLM_HOST=localhost         # Host do servi√ßo LLM (LM Studio)
LLM_PORT=11434             # Porta do servi√ßo LLM
LLM_URL=...                # URL completa do servi√ßo LLM
LLM_MODEL_NAME=gemma:7b    # Nome do modelo LLM a ser utilizado
LLM_MAX_TOKENS=512         # N√∫mero m√°ximo de tokens na resposta
LLM_TEMPERATURE=0.3        # Temperatura do modelo (criatividade)
LLM_TOP_P=0.95             # Top-p sampling

# Modelo SpaCy
SPACY_MODEL=pt_core_news_sm # Modelo SpaCy para processamento em PT-BR

# Logs e monitoramento
LOG_LEVEL=INFO             # N√≠vel de log (DEBUG, INFO, WARNING, ERROR)
ENABLE_DEBUG=false         # Habilitar modo debug

# Verifica√ß√£o opcional do LM Studio
CHECK_LM_STUDIO=false      # Define se o script deve verificar conex√£o com LM Studio
```

## Instala√ß√£o e Execu√ß√£o

1. Clone este reposit√≥rio
2. Configure o arquivo `.env.local` conforme suas necessidades
3. Execute o script melhorado `run.bash`

```bash
# Usando o script bash (recomendado)
chmod +x run.bash
./run.bash

# OU usando o script Python diretamente (requer ambiente j√° configurado)
python3 run.py
```

O script `run.bash` agora:
- Verifica a exist√™ncia do arquivo `.env.local`
- Cria/ativa o ambiente virtual automaticamente
- Instala depend√™ncias necess√°rias
- Verifica/instala o modelo SpaCy configurado
- Opcionalmente verifica a conex√£o com o LM Studio
- Inicia o servi√ßo com as configura√ß√µes apropriadas

## Integra√ß√£o com outros servi√ßos

Este servi√ßo se integra com:

- **Aloy Core API**: Recebe requisi√ß√µes e envia os comandos processados
- **LM Studio**: Modelo de linguagem para processamento avan√ßado
- **SpaCy**: Processamento de linguagem natural para classifica√ß√£o e extra√ß√£o
- **Aloy Smarthome**: Execu√ß√£o dos comandos de controle de dispositivos inteligentes

## Arquitetura

- **app/main.py**: Endpoints da API FastAPI
- **app/config.py**: Carregamento de configura√ß√µes do arquivo .env.local
- **app/services/**: Implementa√ß√µes dos servi√ßos de NLP
  - **direct_commands.py**: Processamento direto de comandos sem uso de LLM
  - **orchestrator.py**: Orquestra√ß√£o do fluxo de processamento
  - **spacy_classifier.py**: Classifica√ß√£o de inten√ß√£o usando SpaCy
  - **lmstudio_client.py**: Cliente para comunica√ß√£o com LM Studio
  - **lamp_control.py**: L√≥gica espec√≠fica para comandos de l√¢mpadas
- **app/schemas/**: Modelos de dados usando Pydantic
